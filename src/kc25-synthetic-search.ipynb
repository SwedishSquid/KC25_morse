{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60165ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:57:26.416256Z",
     "iopub.status.busy": "2025-04-20T14:57:26.415957Z",
     "iopub.status.idle": "2025-04-20T14:57:28.289349Z",
     "shell.execute_reply": "2025-04-20T14:57:28.288565Z"
    },
    "papermill": {
     "duration": 1.880453,
     "end_time": "2025-04-20T14:57:28.290904",
     "exception": false,
     "start_time": "2025-04-20T14:57:26.410451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KC25_morse'...\r\n",
      "remote: Enumerating objects: 114, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (114/114), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (81/81), done.\u001b[K\r\n",
      "remote: Total 114 (delta 64), reused 79 (delta 29), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (114/114), 16.83 MiB | 33.39 MiB/s, done.\r\n",
      "Resolving deltas: 100% (64/64), done.\r\n"
     ]
    }
   ],
   "source": [
    "# run in kaggle to fetch repo\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "GITHUB_TOKEN = user_secrets.get_secret(\"GITHUB_MORSE_TOKEN\")\n",
    "USER = \"SwedishSquid\"\n",
    "REPO_NAME = 'KC25_morse'\n",
    "CLONE_URL = f\"https://{USER}:{GITHUB_TOKEN}@github.com/{USER}/{REPO_NAME}.git\"\n",
    "get_ipython().system(f\"git clone {CLONE_URL}\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/KC25_morse/src\")\n",
    "\n",
    "import morse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "933010da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:57:28.300548Z",
     "iopub.status.busy": "2025-04-20T14:57:28.300290Z",
     "iopub.status.idle": "2025-04-20T14:57:41.071923Z",
     "shell.execute_reply": "2025-04-20T14:57:41.070913Z"
    },
    "papermill": {
     "duration": 12.77794,
     "end_time": "2025-04-20T14:57:41.073401",
     "exception": false,
     "start_time": "2025-04-20T14:57:28.295461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Levenshtein\r\n",
      "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\r\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\r\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\r\n",
      "Successfully installed Levenshtein-0.27.1 rapidfuzz-3.13.0\r\n",
      "Collecting MorseCodePy\r\n",
      "  Downloading morsecodepy-4.1.tar.gz (9.5 kB)\r\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Building wheels for collected packages: MorseCodePy\r\n",
      "  Building wheel for MorseCodePy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for MorseCodePy: filename=morsecodepy-4.1-py3-none-any.whl size=10436 sha256=e75c41630d51b6cd856b1f67bb1501a9d98047ed2e2db3138a4598dbf14add2b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/53/d8/509247fdfc5da7dca8ed7c371f13a91fc94fc83c12cb8ce4e6\r\n",
      "Successfully built MorseCodePy\r\n",
      "Installing collected packages: MorseCodePy\r\n",
      "Successfully installed MorseCodePy-4.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install Levenshtein\n",
    "!pip install MorseCodePy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34671e41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:57:41.084564Z",
     "iopub.status.busy": "2025-04-20T14:57:41.083839Z",
     "iopub.status.idle": "2025-04-20T14:57:43.792344Z",
     "shell.execute_reply": "2025-04-20T14:57:43.791570Z"
    },
    "papermill": {
     "duration": 2.715833,
     "end_time": "2025-04-20T14:57:43.794180",
     "exception": false,
     "start_time": "2025-04-20T14:57:41.078347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "secret_value_0 = UserSecretsClient().get_secret('WANDB_API_KEY')\n",
    "os.environ[\"WANDB_API_KEY\"] = secret_value_0\n",
    "\n",
    "common_wandb_kvals = {\n",
    "    'project': 'KC25',\n",
    "    'entity': 'fishwere',\n",
    "}\n",
    "\n",
    "# let there be no noise\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380b577a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:57:43.806577Z",
     "iopub.status.busy": "2025-04-20T14:57:43.806090Z",
     "iopub.status.idle": "2025-04-20T14:57:51.403260Z",
     "shell.execute_reply": "2025-04-20T14:57:51.402546Z"
    },
    "papermill": {
     "duration": 7.604754,
     "end_time": "2025-04-20T14:57:51.404791",
     "exception": false,
     "start_time": "2025-04-20T14:57:43.800037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "import time\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "from morse.models import CNNResidualBlock, TransformerResidualBlock, PoolingTransition, CNNTransformer, CTCHead\n",
    "from morse.models import MySomething\n",
    "from morse.models import SimpleCNN\n",
    "from morse.my_datasets import ListDataset, load_tensors, filenames_to_torch\n",
    "from morse.samplers import LongCTCSampler\n",
    "# from morse.augmentations import rotation_transform, volume_signal_transform\n",
    "from morse.augmentations import make_volume_signal_transform, make_compose_transform, make_noise_signal_transform, make_runtime_rotation_transform, make_runtime_mel_bounded_noise_transform\n",
    "from morse.text_helpers import Vectorizer, encode_to_morse, decode_from_morse\n",
    "\n",
    "from morse.my_datasets import generate_dataset, read_dataset_from_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f82e999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:57:51.416957Z",
     "iopub.status.busy": "2025-04-20T14:57:51.416434Z",
     "iopub.status.idle": "2025-04-20T14:57:51.520763Z",
     "shell.execute_reply": "2025-04-20T14:57:51.520006Z"
    },
    "papermill": {
     "duration": 0.111743,
     "end_time": "2025-04-20T14:57:51.522114",
     "exception": false,
     "start_time": "2025-04-20T14:57:51.410371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.opus</td>\n",
       "      <td>03ЩУЫЛПИГХ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.opus</td>\n",
       "      <td>ЪЛТ0ДС6А3Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.opus</td>\n",
       "      <td>5ЭКЫБЗХЯН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.opus</td>\n",
       "      <td>ЖЫЦОИ68КФ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.opus</td>\n",
       "      <td>32Ю7МЫ ЗЛ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     message\n",
       "0  1.opus  03ЩУЫЛПИГХ\n",
       "1  2.opus  ЪЛТ0ДС6А3Г\n",
       "2  3.opus   5ЭКЫБЗХЯН\n",
       "3  4.opus   ЖЫЦОИ68КФ\n",
       "4  5.opus   32Ю7МЫ ЗЛ"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dir = '/kaggle/input/kc25-dataset-copy'\n",
    "audio_dir = '/kaggle/input/kc25-dataset-copy/morse_dataset/morse_dataset'\n",
    "\n",
    "\n",
    "dev_flag = False\n",
    "\n",
    "fake_train_set_size = 1000 if dev_flag else 30000\n",
    "\n",
    "fake_val_set_size = 200 if dev_flag else 5000\n",
    "\n",
    "real_traintest_size = 200 if dev_flag else 5000\n",
    "\n",
    "\n",
    "full_train_df = pd.read_csv(Path(labels_dir, 'train.csv'))\n",
    "test_df = pd.read_csv(Path(labels_dir, 'test.csv'))\n",
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb59e7e",
   "metadata": {
    "papermill": {
     "duration": 0.005057,
     "end_time": "2025-04-20T14:57:51.532606",
     "exception": false,
     "start_time": "2025-04-20T14:57:51.527549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b16ac8a",
   "metadata": {
    "papermill": {
     "duration": 0.004838,
     "end_time": "2025-04-20T14:57:51.542374",
     "exception": false,
     "start_time": "2025-04-20T14:57:51.537536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ce3b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:57:51.554186Z",
     "iopub.status.busy": "2025-04-20T14:57:51.553452Z",
     "iopub.status.idle": "2025-04-20T14:57:51.556940Z",
     "shell.execute_reply": "2025-04-20T14:57:51.556320Z"
    },
    "papermill": {
     "duration": 0.010712,
     "end_time": "2025-04-20T14:57:51.558022",
     "exception": false,
     "start_time": "2025-04-20T14:57:51.547310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# signal_tr = make_compose_transform([\n",
    "#     make_volume_signal_transform(min_res=0.1),\n",
    "#     make_noise_signal_transform(),\n",
    "# ])\n",
    "\n",
    "# bounded_noise_tr = make_runtime_mel_bounded_noise_transform()\n",
    "\n",
    "# fake_train_set = generate_dataset(fake_train_set_size, signal_transform=signal_tr, mel_spec_transform=bounded_noise_tr, \n",
    "#                                   runtime_transform=make_runtime_rotation_transform())\n",
    "# fake_val_set = generate_dataset(fake_val_set_size, signal_transform=signal_tr, mel_spec_transform=bounded_noise_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a41aebd",
   "metadata": {
    "papermill": {
     "duration": 0.004717,
     "end_time": "2025-04-20T14:57:51.567624",
     "exception": false,
     "start_time": "2025-04-20T14:57:51.562907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db89d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:57:51.578165Z",
     "iopub.status.busy": "2025-04-20T14:57:51.577957Z",
     "iopub.status.idle": "2025-04-20T15:01:14.916734Z",
     "shell.execute_reply": "2025-04-20T15:01:14.915741Z"
    },
    "papermill": {
     "duration": 203.345549,
     "end_time": "2025-04-20T15:01:14.918217",
     "exception": false,
     "start_time": "2025-04-20T14:57:51.572668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [03:23<00:00, 24.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_index, val_index = train_test_split(np.arange(full_train_df.shape[0]), test_size=1/6, shuffle=True, \n",
    "                                           random_state=42)\n",
    "# real_val_set = read_dataset_from_files(audio_dir, \n",
    "#                                        filenames = full_train_df.iloc[val_index]['id'], \n",
    "#                                        labels=list(full_train_df.iloc[val_index]['message']))\n",
    "# print(len(real_val_set))\n",
    "\n",
    "real_traintest_set = read_dataset_from_files(audio_dir, \n",
    "                                       filenames = full_train_df.iloc[train_index]['id'][:real_traintest_size], \n",
    "                                       labels=list(full_train_df.iloc[train_index]['message'][:real_traintest_size]))\n",
    "print(len(real_traintest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8617bddc",
   "metadata": {
    "papermill": {
     "duration": 0.072554,
     "end_time": "2025-04-20T15:01:15.062032",
     "exception": false,
     "start_time": "2025-04-20T15:01:14.989478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7819202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:01:15.207350Z",
     "iopub.status.busy": "2025-04-20T15:01:15.206236Z",
     "iopub.status.idle": "2025-04-20T15:01:15.210888Z",
     "shell.execute_reply": "2025-04-20T15:01:15.210216Z"
    },
    "papermill": {
     "duration": 0.077711,
     "end_time": "2025-04-20T15:01:15.211988",
     "exception": false,
     "start_time": "2025-04-20T15:01:15.134277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# star_filenames = test_df['id'][-17:][:6]\n",
    "# star_morse = [\n",
    "#     '-.. .- -- .. -. .- -- - / -.. --- - .. / .-. ... -.-- ... .- -- -.-. ..',\n",
    "#     '.. .-.. / -..- ... .-- . -.. - -.- ---. .-- -. - .. / .-.- -- -.. -- -.-- -- ..-- -. .-.- -- -.-. / ..-- - .. -.-- -- -..- - -.- - ---. -- -.-- -. / -.. - -.-- -- .-. --. --.. / . .--. .. --.',\n",
    "#     '.- -. .... / .-- ... --- . --. -..- / .-. / .-- -.- - -.. .- -- .. / -. -.- ---- -- -.. -. .. / --. . -.- -. ...- - .-',\n",
    "#     '.. .-.. / -.. .- ... -.. .--. / -..- ... --- . -- ..- -. - .. / .. --. .-- -.- ... --- . .--. / -..- -.- ... .... -.-- ... ..- ... / .... -. ..- / ..-- -. / .... -. .... -. ..- ... ..',\n",
    "#     '. - -..- - -.- .--. / -.. ... .-.- -. -.- -- -.-- --- -.-. / .. -- -.-',\n",
    "#     '-.- -. --- -..- -.- -- / ... --- . -. -.-- -- --- .--. / -..- ... ..-- -. .-- --',\n",
    "# ]\n",
    "# star_dataset = read_dataset_from_files(audio_dir, filenames=star_filenames, labels=[decode_from_morse(m) for m in star_morse])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14654952",
   "metadata": {
    "papermill": {
     "duration": 0.072077,
     "end_time": "2025-04-20T15:01:15.357760",
     "exception": false,
     "start_time": "2025-04-20T15:01:15.285683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# some helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffe7b89a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:01:15.539320Z",
     "iopub.status.busy": "2025-04-20T15:01:15.538992Z",
     "iopub.status.idle": "2025-04-20T15:01:15.566994Z",
     "shell.execute_reply": "2025-04-20T15:01:15.566138Z"
    },
    "papermill": {
     "duration": 0.138414,
     "end_time": "2025-04-20T15:01:15.568406",
     "exception": false,
     "start_time": "2025-04-20T15:01:15.429992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '#', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я']\n",
      "44\n",
      "{' ': 0, '#': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, 'А': 12, 'Б': 13, 'В': 14, 'Г': 15, 'Д': 16, 'Е': 17, 'Ж': 18, 'З': 19, 'И': 20, 'Й': 21, 'К': 22, 'Л': 23, 'М': 24, 'Н': 25, 'О': 26, 'П': 27, 'Р': 28, 'С': 29, 'Т': 30, 'У': 31, 'Ф': 32, 'Х': 33, 'Ц': 34, 'Ч': 35, 'Ш': 36, 'Щ': 37, 'Ъ': 38, 'Ы': 39, 'Ь': 40, 'Э': 41, 'Ю': 42, 'Я': 43}\n",
      "tensor([27, 28, 20, 14, 17, 30,  0,  1])\n"
     ]
    }
   ],
   "source": [
    "index_to_letter = sorted(set(''.join(full_train_df['message'])))\n",
    "pad_value = 0\n",
    "print(index_to_letter)\n",
    "letter_to_index = dict([(letter, i) for i, letter in enumerate(index_to_letter)])\n",
    "dictionary_size = len(index_to_letter)\n",
    "print(dictionary_size)\n",
    "print(letter_to_index)\n",
    "\n",
    "vectorizer = Vectorizer(letter_to_index, index_to_letter)\n",
    "print(vectorizer.text_transform('ПРИВЕТ #'))\n",
    "\n",
    "\n",
    "def batch_text_transform(texts):\n",
    "    vecs, lengths = vectorizer.batch_text_transform(texts, pad_value=pad_value)\n",
    "    return vecs + 1, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c1d8821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:01:15.723382Z",
     "iopub.status.busy": "2025-04-20T15:01:15.722982Z",
     "iopub.status.idle": "2025-04-20T15:01:15.802752Z",
     "shell.execute_reply": "2025-04-20T15:01:15.801931Z"
    },
    "papermill": {
     "duration": 0.162761,
     "end_time": "2025-04-20T15:01:15.804284",
     "exception": false,
     "start_time": "2025-04-20T15:01:15.641523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d8e24",
   "metadata": {
    "papermill": {
     "duration": 0.093053,
     "end_time": "2025-04-20T15:01:15.976831",
     "exception": false,
     "start_time": "2025-04-20T15:01:15.883778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cd000a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:01:16.120017Z",
     "iopub.status.busy": "2025-04-20T15:01:16.119251Z",
     "iopub.status.idle": "2025-04-20T15:01:16.124507Z",
     "shell.execute_reply": "2025-04-20T15:01:16.123782Z"
    },
    "papermill": {
     "duration": 0.078877,
     "end_time": "2025-04-20T15:01:16.125722",
     "exception": false,
     "start_time": "2025-04-20T15:01:16.046845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 3 if dev_flag else 30\n",
    "batch_size = 128\n",
    "\n",
    "lr = 1e-3\n",
    "step_gamma = 0.33\n",
    "dropout = 0.165\n",
    "\n",
    "n_pools = 4\n",
    "n_blocks_before_pool = 3\n",
    "pooling_overlap = True\n",
    "\n",
    "group = 'SyntheticDataSearch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6526a3d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:01:16.282113Z",
     "iopub.status.busy": "2025-04-20T15:01:16.281739Z",
     "iopub.status.idle": "2025-04-20T15:11:37.200199Z",
     "shell.execute_reply": "2025-04-20T15:11:37.198990Z"
    },
    "papermill": {
     "duration": 620.997653,
     "end_time": "2025-04-20T15:11:37.202705",
     "exception": false,
     "start_time": "2025-04-20T15:01:16.205052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 18.64it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.58it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.210727262496949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 37.08it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.960347661972046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.29it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.36it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.314725569605827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.33it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.85it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 39.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.166647103631496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.30it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.70it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3393262873518466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.35it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7614910895923375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.36it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.97it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3566136237690567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.71it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.062861314783176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.40it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8549210071154197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.34it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.66it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7104847687196167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.36it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.10it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 41.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6127140134968363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.78it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.550962653485795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.34it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.14it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5014898992672583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.35it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.64it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.471555912690015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.33it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4472293873008648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4405026479128591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.33it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.70it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42619568114424883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.34it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.74it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40954400006395175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.40it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.39it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4030538651587875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.25it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3940638469924149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.91it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 46.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39061361820387164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.38it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 46.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3870326359035683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.87it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3865367288662471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.26it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38745373693023466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.19it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.29it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3847221567714218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.31it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3824182961522343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.24it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 41.61it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3830247819321515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.29it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.88it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3843936204838766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.26it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.17it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3847901260802755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.85it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3828575755322701\n"
     ]
    }
   ],
   "source": [
    "run_name = 'testrun' if dev_flag else 'best_guess'\n",
    "\n",
    "volume_tr_min_res=0.2\n",
    "volume_tr_max_freq=1.26\n",
    "noise_signal_tr__max_volume = 1.83\n",
    "noise_signal_tr__prob = 0.6\n",
    "\n",
    "bounded_noise_tr__prob = 0.96\n",
    "bounded_noise_tr__max_volume = 0.6\n",
    "bounded_noise_tr__std_frac_bounds = 0.12\n",
    "\n",
    "inner_dot_duration_multiplier_deviation = 0.21\n",
    "\n",
    "runtime_rotation_transform__prob = 0.1\n",
    "\n",
    "config = {\n",
    "    'n_epochs': n_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    \n",
    "    'lr': lr,\n",
    "    'step_gamma': step_gamma,\n",
    "    'dropout': dropout,\n",
    "\n",
    "    'n_pools': n_pools,\n",
    "    'n_blocks_before_pool': n_blocks_before_pool,\n",
    "    'pooling_overlap': pooling_overlap,\n",
    "\n",
    "    'volume_tr_min_res': volume_tr_min_res,\n",
    "    'volume_tr_max_freq': volume_tr_max_freq,\n",
    "    'noise_signal_tr__max_volume': noise_signal_tr__max_volume,\n",
    "    'noise_signal_tr__prob': noise_signal_tr__prob,\n",
    "\n",
    "    'bounded_noise_tr__prob': bounded_noise_tr__prob,\n",
    "    'bounded_noise_tr__max_volume': bounded_noise_tr__max_volume,\n",
    "    'bounded_noise_tr__std_frac_bounds': bounded_noise_tr__std_frac_bounds,\n",
    "\n",
    "    'inner_dot_duration_multiplier_deviation': inner_dot_duration_multiplier_deviation,\n",
    "\n",
    "    'runtime_rotation_transform__prob': runtime_rotation_transform__prob,\n",
    "}\n",
    "\n",
    "signal_tr = make_compose_transform([\n",
    "    make_volume_signal_transform(min_res=volume_tr_min_res, max_freq=volume_tr_max_freq),\n",
    "    make_noise_signal_transform(max_volume=noise_signal_tr__max_volume, p=noise_signal_tr__prob),\n",
    "])\n",
    "\n",
    "bounded_noise_tr = make_runtime_mel_bounded_noise_transform(std_frac_bounds=(0.015, bounded_noise_tr__std_frac_bounds),\n",
    "                                                             volume_bounds=(0, bounded_noise_tr__max_volume),\n",
    "                                                             p=bounded_noise_tr__prob)\n",
    "\n",
    "inner_dot_duration_multiplier_range=(1 - inner_dot_duration_multiplier_deviation, 1 + inner_dot_duration_multiplier_deviation)\n",
    "\n",
    "print('dataset creation')\n",
    "\n",
    "fake_train_set = generate_dataset(fake_train_set_size, signal_transform=signal_tr, mel_spec_transform=bounded_noise_tr,\n",
    "                                  runtime_transform=make_runtime_rotation_transform(p=runtime_rotation_transform__prob),\n",
    "                                  inner_dot_duration_multiplier_range=inner_dot_duration_multiplier_range, show_pbar=False)\n",
    "fake_val_set = generate_dataset(fake_val_set_size, signal_transform=signal_tr, mel_spec_transform=bounded_noise_tr,\n",
    "                                 inner_dot_duration_multiplier_range=inner_dot_duration_multiplier_range, show_pbar=False)\n",
    "\n",
    "model = SimpleCNN(d_input=64, d_model=64, d_inner=64, d_output=dictionary_size + 1, \n",
    "              n_pools=n_pools, n_blocks_before_pool=n_blocks_before_pool, pooling_overlap=pooling_overlap,\n",
    "              dropout=dropout).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20], gamma=step_gamma)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "\n",
    "\n",
    "fake_train_loader = torch.utils.data.DataLoader(fake_train_set, batch_size=batch_size, shuffle=True)\n",
    "fake_val_loader = torch.utils.data.DataLoader(fake_val_set, batch_size=batch_size, shuffle=False)\n",
    "real_traintest_loader = torch.utils.data.DataLoader(real_traintest_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "average_traintest_loss = 10\n",
    "averaging_speed = 0.3\n",
    "\n",
    "with wandb.init(\n",
    "    **common_wandb_kvals,\n",
    "    group=group,\n",
    "    config=config,\n",
    "    name=run_name,\n",
    "    ) as run:\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        fake_train_loss_buffer = []\n",
    "        for features, labels in tqdm(fake_train_loader):\n",
    "            features = features.to(device)\n",
    "            targets, target_lengths = batch_text_transform(labels)\n",
    "            targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "            outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "            inputs = F.log_softmax(outs, dim=2)\n",
    "            input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "            loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            fake_train_loss_buffer.append(loss.detach())\n",
    "        scheduler.step()\n",
    "    \n",
    "        model.eval()\n",
    "        fake_val_loss_buffer = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in tqdm(fake_val_loader):\n",
    "                features = features.to(device)\n",
    "                targets, target_lengths = batch_text_transform(labels)\n",
    "                targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "                outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "                inputs = F.log_softmax(outs, dim=2)\n",
    "                input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "                loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "                fake_val_loss_buffer.append(loss.detach())\n",
    "\n",
    "        model.eval()\n",
    "        real_traintest_loss_buffer = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in tqdm(real_traintest_loader):\n",
    "                features = features.to(device)\n",
    "                targets, target_lengths = batch_text_transform(labels)\n",
    "                targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "                outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "                inputs = F.log_softmax(outs, dim=2)\n",
    "                input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "                loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "                real_traintest_loss_buffer.append(loss.detach())\n",
    "        \n",
    "        # model.eval()\n",
    "        # star_loss_buffer = []\n",
    "        # star_len_buffer = []\n",
    "        # star_dist_buffer = []\n",
    "        # with torch.no_grad():\n",
    "        #     for features, labels in tqdm(star_dataset):\n",
    "        #         features = features[None]\n",
    "        #         labels = [labels]\n",
    "        #         features = features.to(device)\n",
    "        #         targets, target_lengths = batch_text_transform(labels)\n",
    "        #         targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "        #         outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "\n",
    "        #         probs = F.softmax(outs, dim=0).detach().to('cpu').squeeze().transpose(0, 1)\n",
    "        #         seqs, likelihood = LongCTCSampler.sample(probs, beam_size=10)\n",
    "        #         text = vectorizer.from_tensor(torch.tensor(seqs) - 1)\n",
    "        #         dist = Levenshtein.distance(text, labels[0])\n",
    "        #         star_dist_buffer.append(dist)\n",
    "                \n",
    "        #         inputs = F.log_softmax(outs, dim=2)\n",
    "        #         input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "        #         loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "        #         star_len_buffer.append(len(labels[0]))\n",
    "        #         star_loss_buffer.append(loss.detach())\n",
    "    \n",
    "        fake_train_loss_value = torch.mean(torch.stack(fake_train_loss_buffer)).item()\n",
    "        fake_val_loss_value = torch.mean(torch.stack(fake_val_loss_buffer)).item()\n",
    "        real_traintest_loss_value = torch.mean(torch.stack(real_traintest_loss_buffer)).item()\n",
    "        # star_loss_value = torch.mean(torch.stack(star_loss_buffer)).item()\n",
    "        # star_dist_value = np.mean(star_dist_buffer)\n",
    "\n",
    "        average_traintest_loss = real_traintest_loss_value * averaging_speed + average_traintest_loss * (1 - averaging_speed)\n",
    "\n",
    "        print(average_traintest_loss)\n",
    "\n",
    "        wandb.log({\n",
    "            'fake_train_loss': fake_train_loss_value,\n",
    "            'fake_val_loss': fake_val_loss_value,\n",
    "            'real_traintest_loss': real_traintest_loss_value,\n",
    "            # 'star_loss': star_loss_value,\n",
    "            # 'star_dist': star_dist_value,\n",
    "            'lr': scheduler.get_last_lr()[0],\n",
    "            'average_traintest_loss': average_traintest_loss,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7b8d202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:11:37.670334Z",
     "iopub.status.busy": "2025-04-20T15:11:37.670054Z",
     "iopub.status.idle": "2025-04-20T15:11:37.676981Z",
     "shell.execute_reply": "2025-04-20T15:11:37.676318Z"
    },
    "papermill": {
     "duration": 0.196967,
     "end_time": "2025-04-20T15:11:37.678188",
     "exception": false,
     "start_time": "2025-04-20T15:11:37.481221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# def objective(trial: optuna.Trial):\n",
    "#     run_name = 'testrun' if dev_flag else None\n",
    "\n",
    "#     volume_tr_min_res=trial.suggest_float('volume_tr_min_res', 0, 0.3)\n",
    "#     volume_tr_max_freq=trial.suggest_float('volume_tr_max_freq', 0.3, 2)\n",
    "#     noise_signal_tr__max_volume = trial.suggest_float('noise_signal_tr__max_volume', 0, 2)\n",
    "#     noise_signal_tr__prob = trial.suggest_float('noise_signal_tr__prob', 0, 1)\n",
    "\n",
    "#     bounded_noise_tr__prob = trial.suggest_float('bounded_noise_tr__prob', 0, 1)\n",
    "#     bounded_noise_tr__max_volume = trial.suggest_float('bounded_noise_tr__max_volume', 0, 1.2)\n",
    "#     bounded_noise_tr__std_frac_bounds = trial.suggest_float('bounded_noise_tr__std_frac_bounds', 0.02, 0.2)\n",
    "\n",
    "#     inner_dot_duration_multiplier_deviation = trial.suggest_float('inner_dot_duration_multiplier_deviation', 0, 0.3)\n",
    "\n",
    "#     runtime_rotation_transform__prob = trial.suggest_float('runtime_rotation_transform__prob', 0, 1)\n",
    "\n",
    "#     config = {\n",
    "#         'n_epochs': n_epochs,\n",
    "#         'batch_size': batch_size,\n",
    "        \n",
    "#         'lr': lr,\n",
    "#         'step_gamma': step_gamma,\n",
    "#         'dropout': dropout,\n",
    "\n",
    "#         'n_pools': n_pools,\n",
    "#         'n_blocks_before_pool': n_blocks_before_pool,\n",
    "#         'pooling_overlap': pooling_overlap,\n",
    "\n",
    "#         'volume_tr_min_res': volume_tr_min_res,\n",
    "#         'volume_tr_max_freq': volume_tr_max_freq,\n",
    "#         'noise_signal_tr__max_volume': noise_signal_tr__max_volume,\n",
    "#         'noise_signal_tr__prob': noise_signal_tr__prob,\n",
    "\n",
    "#         'bounded_noise_tr__prob': bounded_noise_tr__prob,\n",
    "#         'bounded_noise_tr__max_volume': bounded_noise_tr__max_volume,\n",
    "#         'bounded_noise_tr__std_frac_bounds': bounded_noise_tr__std_frac_bounds,\n",
    "\n",
    "#         'inner_dot_duration_multiplier_deviation': inner_dot_duration_multiplier_deviation,\n",
    "\n",
    "#         'runtime_rotation_transform__prob': runtime_rotation_transform__prob,\n",
    "#     }\n",
    "\n",
    "#     signal_tr = make_compose_transform([\n",
    "#         make_volume_signal_transform(min_res=volume_tr_min_res, max_freq=volume_tr_max_freq),\n",
    "#         make_noise_signal_transform(max_volume=noise_signal_tr__max_volume, p=noise_signal_tr__prob),\n",
    "#     ])\n",
    "\n",
    "#     bounded_noise_tr = make_runtime_mel_bounded_noise_transform(std_frac_bounds=(0.015, bounded_noise_tr__std_frac_bounds),\n",
    "#                                                                  volume_bounds=(0, bounded_noise_tr__max_volume),\n",
    "#                                                                  p=bounded_noise_tr__prob)\n",
    "\n",
    "#     inner_dot_duration_multiplier_range=(1 - inner_dot_duration_multiplier_deviation, 1 + inner_dot_duration_multiplier_deviation)\n",
    "\n",
    "#     print('dataset creation')\n",
    "\n",
    "#     fake_train_set = generate_dataset(fake_train_set_size, signal_transform=signal_tr, mel_spec_transform=bounded_noise_tr,\n",
    "#                                       runtime_transform=make_runtime_rotation_transform(p=runtime_rotation_transform__prob),\n",
    "#                                       inner_dot_duration_multiplier_range=inner_dot_duration_multiplier_range, show_pbar=False)\n",
    "#     fake_val_set = generate_dataset(fake_val_set_size, signal_transform=signal_tr, mel_spec_transform=bounded_noise_tr,\n",
    "#                                      inner_dot_duration_multiplier_range=inner_dot_duration_multiplier_range, show_pbar=False)\n",
    "\n",
    "#     model = SimpleCNN(d_input=64, d_model=64, d_inner=64, d_output=dictionary_size + 1, \n",
    "#                   n_pools=n_pools, n_blocks_before_pool=n_blocks_before_pool, pooling_overlap=pooling_overlap,\n",
    "#                   dropout=dropout).to(device)\n",
    "\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "#     scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20], gamma=step_gamma)\n",
    "#     ctc_loss = nn.CTCLoss()\n",
    "\n",
    "\n",
    "#     fake_train_loader = torch.utils.data.DataLoader(fake_train_set, batch_size=batch_size, shuffle=True)\n",
    "#     fake_val_loader = torch.utils.data.DataLoader(fake_val_set, batch_size=batch_size, shuffle=False)\n",
    "#     real_traintest_loader = torch.utils.data.DataLoader(real_traintest_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "#     average_traintest_loss = 10\n",
    "#     averaging_speed = 0.3\n",
    "\n",
    "#     with wandb.init(\n",
    "#         **common_wandb_kvals,\n",
    "#         group=group,\n",
    "#         config=config,\n",
    "#         name=run_name,\n",
    "#         ) as run:\n",
    "#         for epoch in range(n_epochs):\n",
    "#             model.train()\n",
    "#             fake_train_loss_buffer = []\n",
    "#             for features, labels in tqdm(fake_train_loader):\n",
    "#                 features = features.to(device)\n",
    "#                 targets, target_lengths = batch_text_transform(labels)\n",
    "#                 targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "#                 outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "#                 inputs = F.log_softmax(outs, dim=2)\n",
    "#                 input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "#                 loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 optimizer.zero_grad()\n",
    "#                 fake_train_loss_buffer.append(loss.detach())\n",
    "#             scheduler.step()\n",
    "        \n",
    "#             model.eval()\n",
    "#             fake_val_loss_buffer = []\n",
    "#             with torch.no_grad():\n",
    "#                 for features, labels in tqdm(fake_val_loader):\n",
    "#                     features = features.to(device)\n",
    "#                     targets, target_lengths = batch_text_transform(labels)\n",
    "#                     targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "#                     outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "#                     inputs = F.log_softmax(outs, dim=2)\n",
    "#                     input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "#                     loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "#                     fake_val_loss_buffer.append(loss.detach())\n",
    "\n",
    "#             model.eval()\n",
    "#             real_traintest_loss_buffer = []\n",
    "#             with torch.no_grad():\n",
    "#                 for features, labels in tqdm(real_traintest_loader):\n",
    "#                     features = features.to(device)\n",
    "#                     targets, target_lengths = batch_text_transform(labels)\n",
    "#                     targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "#                     outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "#                     inputs = F.log_softmax(outs, dim=2)\n",
    "#                     input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "#                     loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "#                     real_traintest_loss_buffer.append(loss.detach())\n",
    "            \n",
    "#             # model.eval()\n",
    "#             # star_loss_buffer = []\n",
    "#             # star_len_buffer = []\n",
    "#             # star_dist_buffer = []\n",
    "#             # with torch.no_grad():\n",
    "#             #     for features, labels in tqdm(star_dataset):\n",
    "#             #         features = features[None]\n",
    "#             #         labels = [labels]\n",
    "#             #         features = features.to(device)\n",
    "#             #         targets, target_lengths = batch_text_transform(labels)\n",
    "#             #         targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "#             #         outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "\n",
    "#             #         probs = F.softmax(outs, dim=0).detach().to('cpu').squeeze().transpose(0, 1)\n",
    "#             #         seqs, likelihood = LongCTCSampler.sample(probs, beam_size=10)\n",
    "#             #         text = vectorizer.from_tensor(torch.tensor(seqs) - 1)\n",
    "#             #         dist = Levenshtein.distance(text, labels[0])\n",
    "#             #         star_dist_buffer.append(dist)\n",
    "                    \n",
    "#             #         inputs = F.log_softmax(outs, dim=2)\n",
    "#             #         input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "#             #         loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "#             #         star_len_buffer.append(len(labels[0]))\n",
    "#             #         star_loss_buffer.append(loss.detach())\n",
    "        \n",
    "#             fake_train_loss_value = torch.mean(torch.stack(fake_train_loss_buffer)).item()\n",
    "#             fake_val_loss_value = torch.mean(torch.stack(fake_val_loss_buffer)).item()\n",
    "#             real_traintest_loss_value = torch.mean(torch.stack(real_traintest_loss_buffer)).item()\n",
    "#             # star_loss_value = torch.mean(torch.stack(star_loss_buffer)).item()\n",
    "#             # star_dist_value = np.mean(star_dist_buffer)\n",
    "\n",
    "#             average_traintest_loss = real_traintest_loss_value * averaging_speed + average_traintest_loss * (1 - averaging_speed)\n",
    "\n",
    "#             print(average_traintest_loss)\n",
    "\n",
    "#             wandb.log({\n",
    "#                 'fake_train_loss': fake_train_loss_value,\n",
    "#                 'fake_val_loss': fake_val_loss_value,\n",
    "#                 'real_traintest_loss': real_traintest_loss_value,\n",
    "#                 # 'star_loss': star_loss_value,\n",
    "#                 # 'star_dist': star_dist_value,\n",
    "#                 'lr': scheduler.get_last_lr()[0],\n",
    "#                 'average_traintest_loss': average_traintest_loss,\n",
    "#             })\n",
    "\n",
    "#     return average_traintest_loss\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e2390c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:11:38.052027Z",
     "iopub.status.busy": "2025-04-20T15:11:38.051474Z",
     "iopub.status.idle": "2025-04-20T15:11:38.055064Z",
     "shell.execute_reply": "2025-04-20T15:11:38.054483Z"
    },
    "papermill": {
     "duration": 0.190814,
     "end_time": "2025-04-20T15:11:38.056193",
     "exception": false,
     "start_time": "2025-04-20T15:11:37.865379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "109769f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:11:38.481040Z",
     "iopub.status.busy": "2025-04-20T15:11:38.480383Z",
     "iopub.status.idle": "2025-04-20T15:11:38.502697Z",
     "shell.execute_reply": "2025-04-20T15:11:38.501660Z"
    },
    "papermill": {
     "duration": 0.262337,
     "end_time": "2025-04-20T15:11:38.504130",
     "exception": false,
     "start_time": "2025-04-20T15:11:38.241793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{run_name}.pt')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7109828,
     "sourceId": 11359850,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 860.721347,
   "end_time": "2025-04-20T15:11:42.741813",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-20T14:57:22.020466",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
