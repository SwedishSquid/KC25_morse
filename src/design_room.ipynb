{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "import time\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "from morse.models import CNNResidualBlock, TransformerResidualBlock, PoolingTransition, CNNTransformer, CTCHead\n",
    "from morse.models import MySomething\n",
    "from morse.models import SimpleCNN\n",
    "from morse.my_datasets import ListDataset, load_tensors, filenames_to_torch\n",
    "from morse.samplers import LongCTCSampler\n",
    "# from morse.augmentations import rotation_transform, volume_signal_transform\n",
    "from morse.augmentations import make_volume_signal_transform, make_compose_transform, make_noise_signal_transform, make_runtime_rotation_transform, make_runtime_mel_bounded_noise_transform, make_mel_pad_augmentation\n",
    "from morse.text_helpers import Vectorizer, encode_to_morse, decode_from_morse\n",
    "\n",
    "from morse.my_datasets import generate_dataset, read_dataset_from_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.opus</td>\n",
       "      <td>03ЩУЫЛПИГХ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.opus</td>\n",
       "      <td>ЪЛТ0ДС6А3Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.opus</td>\n",
       "      <td>5ЭКЫБЗХЯН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.opus</td>\n",
       "      <td>ЖЫЦОИ68КФ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.opus</td>\n",
       "      <td>32Ю7МЫ ЗЛ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     message\n",
       "0  1.opus  03ЩУЫЛПИГХ\n",
       "1  2.opus  ЪЛТ0ДС6А3Г\n",
       "2  3.opus   5ЭКЫБЗХЯН\n",
       "3  4.opus   ЖЫЦОИ68КФ\n",
       "4  5.opus   32Ю7МЫ ЗЛ"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dir = '../'\n",
    "audio_dir = '../morse_dataset'\n",
    "\n",
    "\n",
    "dev_flag = True\n",
    "\n",
    "\n",
    "full_train_df = pd.read_csv(Path(labels_dir, 'train.csv'))\n",
    "test_df = pd.read_csv(Path(labels_dir, 'test.csv'))\n",
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 29.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_index, val_index = train_test_split(np.arange(full_train_df.shape[0]), test_size=1/6, shuffle=True, \n",
    "                                           random_state=42)\n",
    "\n",
    "val_index = val_index[:100]\n",
    "\n",
    "real_val_set = read_dataset_from_files(audio_dir, \n",
    "                                       filenames = full_train_df.iloc[val_index]['id'], \n",
    "                                       labels=list(full_train_df.iloc[val_index]['message']), \n",
    "                                       mel_spec_transform=make_mel_pad_augmentation())\n",
    "print(len(real_val_set))\n",
    "\n",
    "# real_train_set = read_dataset_from_files(audio_dir, \n",
    "#                                        filenames = full_train_df.iloc[train_index]['id'], \n",
    "#                                        labels=list(full_train_df.iloc[train_index]['message']))\n",
    "# print(len(real_train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartialFlatUNetBlock(nn.Module):\n",
    "    def __init__(self, n_down, n_up, \n",
    "                 make_regular_block,\n",
    "                 central_block,\n",
    "                 make_downsample_transition,\n",
    "                 make_upsample_transition):\n",
    "        super().__init__()\n",
    "        self.down_compute_blocks = nn.ModuleList([make_regular_block() for _ in range(n_down)])\n",
    "        self.downsample_transitions = nn.ModuleList([make_downsample_transition() for _ in range(n_down)])\n",
    "        self.central_block = central_block\n",
    "        self.up_compute_blocks = nn.ModuleList([make_regular_block() for _ in range(n_up)])\n",
    "        self.upsample_transitions = nn.ModuleList([make_upsample_transition() for _ in range(n_up)])\n",
    "        pass\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        residuals = []\n",
    "        for d_comp_block, downsample in zip(self.down_compute_blocks, self.downsample_transitions):\n",
    "            outs = d_comp_block(x)\n",
    "            residuals.append(outs)\n",
    "            x = downsample(outs)\n",
    "        \n",
    "        x = self.central_block(x)\n",
    "\n",
    "        for i, (u_comp_block, upsample) in enumerate(zip(self.up_compute_blocks, self.upsample_transitions)):\n",
    "            res = residuals[-i - 1]\n",
    "            upsampled = upsample(x)\n",
    "            print(res.shape, upsampled.shape)\n",
    "            inputs = res + upsampled\n",
    "            x = u_comp_block(inputs)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.tensor([el[0].numpy() for el in real_val_set])\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 64, 64]) torch.Size([100, 64, 64])\n",
      "torch.Size([100, 64, 128]) torch.Size([100, 64, 128])\n",
      "torch.Size([100, 64, 256]) torch.Size([100, 64, 256])\n",
      "torch.Size([100, 64, 512]) torch.Size([100, 64, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_test_block():\n",
    "    return CNNResidualBlock(d_model=64, d_inner=64)\n",
    "\n",
    "# only well padded inputs\n",
    "\n",
    "PartialFlatUNetBlock(n_down=4, n_up=4, make_regular_block=make_test_block, central_block=make_test_block(), \n",
    "                     make_downsample_transition=lambda: nn.Conv1d(64, 64, kernel_size=2, stride=2, padding=0), \n",
    "                     make_upsample_transition=lambda: nn.ConvTranspose1d(in_channels=64, out_channels=64, kernel_size=2, stride=2,\n",
    "                                                                          padding=0))(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
