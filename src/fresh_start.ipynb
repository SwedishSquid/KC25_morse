{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "import time\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "from morse.models import CNNResidualBlock, TransformerResidualBlock, PoolingTransition, CNNTransformer, CTCHead\n",
    "from morse.models import MySomething\n",
    "from morse.models import SimpleCNN\n",
    "from morse.my_datasets import ListDataset, load_tensors, filenames_to_torch\n",
    "from morse.samplers import LongCTCSampler\n",
    "from morse.augmentations import rotation_transform, volume_signal_transform\n",
    "from morse.text_helpers import Vectorizer, encode_to_morse, decode_from_morse\n",
    "\n",
    "from morse.my_datasets import generate_dataset, read_dataset_from_files\n",
    "from morse.generators import volume_sinusoid_variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.opus</td>\n",
       "      <td>03ЩУЫЛПИГХ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.opus</td>\n",
       "      <td>ЪЛТ0ДС6А3Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.opus</td>\n",
       "      <td>5ЭКЫБЗХЯН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.opus</td>\n",
       "      <td>ЖЫЦОИ68КФ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.opus</td>\n",
       "      <td>32Ю7МЫ ЗЛ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     message\n",
       "0  1.opus  03ЩУЫЛПИГХ\n",
       "1  2.opus  ЪЛТ0ДС6А3Г\n",
       "2  3.opus   5ЭКЫБЗХЯН\n",
       "3  4.opus   ЖЫЦОИ68КФ\n",
       "4  5.opus   32Ю7МЫ ЗЛ"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dir = '../'\n",
    "audio_dir = '../morse_dataset'\n",
    "\n",
    "\n",
    "dev_flag = True\n",
    "\n",
    "fake_dataset_size = 1000 if dev_flag else 30000 \n",
    "\n",
    "full_train_df = pd.read_csv(Path(labels_dir, 'train.csv'))\n",
    "test_df = pd.read_csv(Path(labels_dir, 'test.csv'))\n",
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 324.13it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 323.81it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 258.41it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 258.37it/s]\n"
     ]
    }
   ],
   "source": [
    "fake_train_set = generate_dataset(fake_dataset_size, runtime_transform=rotation_transform)\n",
    "fake_val_set = generate_dataset(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 325.74it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 323.63it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fake_batch = torch.stack([fake_train_set[0][0], fake_train_set[1][0], fake_train_set[2][0]])\n",
    "# print(fake_batch.shape)\n",
    "\n",
    "\n",
    "\n",
    "fake_mel, fake_message = generate_dataset(100, signal_transform=volume_signal_transform, runtime_transform=rotation_transform)[0]\n",
    "plt.imshow(fake_mel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:47<00:00, 105.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_index, val_index = train_test_split(np.arange(full_train_df.shape[0]), test_size=1/6, shuffle=True, \n",
    "                                           random_state=42)\n",
    "real_val_set = read_dataset_from_files(audio_dir, \n",
    "                                       filenames = full_train_df.iloc[val_index]['id'], \n",
    "                                       labels=list(full_train_df.iloc[val_index]['message']))\n",
    "print(len(real_val_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '#', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я']\n",
      "44\n",
      "{' ': 0, '#': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, 'А': 12, 'Б': 13, 'В': 14, 'Г': 15, 'Д': 16, 'Е': 17, 'Ж': 18, 'З': 19, 'И': 20, 'Й': 21, 'К': 22, 'Л': 23, 'М': 24, 'Н': 25, 'О': 26, 'П': 27, 'Р': 28, 'С': 29, 'Т': 30, 'У': 31, 'Ф': 32, 'Х': 33, 'Ц': 34, 'Ч': 35, 'Ш': 36, 'Щ': 37, 'Ъ': 38, 'Ы': 39, 'Ь': 40, 'Э': 41, 'Ю': 42, 'Я': 43}\n",
      "tensor([27, 28, 20, 14, 17, 30,  0,  1])\n"
     ]
    }
   ],
   "source": [
    "index_to_letter = sorted(set(''.join(full_train_df['message'])))\n",
    "pad_value = 0\n",
    "print(index_to_letter)\n",
    "letter_to_index = dict([(letter, i) for i, letter in enumerate(index_to_letter)])\n",
    "dictionary_size = len(index_to_letter)\n",
    "print(dictionary_size)\n",
    "print(letter_to_index)\n",
    "\n",
    "vectorizer = Vectorizer(letter_to_index, index_to_letter)\n",
    "print(vectorizer.text_transform('ПРИВЕТ #'))\n",
    "\n",
    "\n",
    "def batch_text_transform(texts):\n",
    "    vecs, lengths = vectorizer.batch_text_transform(texts, pad_value=pad_value)\n",
    "    return vecs + 1, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "lr = 0.005\n",
    "step_gamma = 0.359\n",
    "dropout = 0.165\n",
    "\n",
    "n_pools = 4\n",
    "n_blocks_before_pool = 3\n",
    "pooling_overlap = True\n",
    "\n",
    "group = 'FreshStart'\n",
    "run_name = 'testing'\n",
    "\n",
    "config = {\n",
    "    'n_epochs': n_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    \n",
    "    'lr': lr,\n",
    "    'step_gamma': step_gamma,\n",
    "    'dropout': dropout,\n",
    "\n",
    "    'n_pools': n_pools,\n",
    "    'n_blocks_before_pool': n_blocks_before_pool,\n",
    "    'pooling_overlap': pooling_overlap,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN(d_input=64, d_model=64, d_inner=64, d_output=dictionary_size + 1, \n",
    "                  n_pools=n_pools, n_blocks_before_pool=n_blocks_before_pool, pooling_overlap=True, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.14it/s]\n",
      "100%|██████████| 40/40 [00:09<00:00,  4.06it/s]\n",
      "100%|██████████| 40/40 [00:09<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  4.478435516357422\n",
      "test:   4.998063087463379\n",
      "real val 5.633488655090332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.54it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  3.101802349090576\n",
      "test:   4.100996971130371\n",
      "real val 7.176459312438965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.30it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.61it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  2.5137369632720947\n",
      "test:   2.7605419158935547\n",
      "real val 7.856261253356934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.31it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.62it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  1.9083642959594727\n",
      "test:   1.747704267501831\n",
      "real val 10.543474197387695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.32it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.76it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  1.2899998426437378\n",
      "test:   1.0219135284423828\n",
      "real val 11.543412208557129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.33it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.46it/s]\n",
      "100%|██████████| 40/40 [00:09<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.8050808310508728\n",
      "test:   0.6387902498245239\n",
      "real val 10.309587478637695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.31it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.70it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.5655008554458618\n",
      "test:   0.5640571117401123\n",
      "real val 10.828984260559082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.30it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.55it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.42763668298721313\n",
      "test:   0.4274771809577942\n",
      "real val 11.7359037399292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.55it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.34071239829063416\n",
      "test:   0.4081993103027344\n",
      "real val 11.37490463256836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:05<00:01,  1.11it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m targets, target_lengths = batch_text_transform(labels)\n\u001b[32m     22\u001b[39m targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m outs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m.transpose(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m     24\u001b[39m inputs = F.log_softmax(outs, dim=\u001b[32m2\u001b[39m)\n\u001b[32m     25\u001b[39m input_lengths = torch.full(size=(inputs.shape[\u001b[32m1\u001b[39m],), fill_value=inputs.shape[\u001b[32m0\u001b[39m], dtype=torch.int32).to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\src\\morse\\models.py:332\u001b[39m, in \u001b[36mSimpleCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor):\n\u001b[32m    331\u001b[39m     \u001b[38;5;66;03m# [batch, channels, seq_len]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m     \u001b[38;5;66;03m# [batch, channels, seq_len]\u001b[39;00m\n\u001b[32m    334\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.head(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\src\\morse\\models.py:106\u001b[39m, in \u001b[36mCNNResidualBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    105\u001b[39m     residual = x\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     out = residual + out\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.post_norm(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    186\u001b[39m     bn_training = (\u001b[38;5;28mself\u001b[39m.running_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_mean\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dev\\ML\\morse\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:2822\u001b[39m, in \u001b[36mbatch_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[39m\n\u001b[32m   2819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m   2820\u001b[39m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2823\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20], gamma=step_gamma)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "\n",
    "\n",
    "fake_train_loader = torch.utils.data.DataLoader(fake_train_set, batch_size=batch_size, shuffle=True)\n",
    "fake_val_loader = torch.utils.data.DataLoader(fake_val_set, batch_size=batch_size, shuffle=False)\n",
    "real_val_loader = torch.utils.data.DataLoader(real_val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# with wandb.init(\n",
    "#         **common_wandb_kvals,\n",
    "#         group=group,\n",
    "#         config=config,\n",
    "#         name=run_name,\n",
    "#         ) as run:\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    fake_train_loss_buffer = []\n",
    "    for features, labels in tqdm(fake_train_loader):\n",
    "        features = features.to(device)\n",
    "        targets, target_lengths = batch_text_transform(labels)\n",
    "        targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "        outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "        inputs = F.log_softmax(outs, dim=2)\n",
    "        input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "        loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        fake_train_loss_buffer.append(loss.detach())\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    fake_val_loss_buffer = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(fake_val_loader):\n",
    "            features = features.to(device)\n",
    "            targets, target_lengths = batch_text_transform(labels)\n",
    "            targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "            outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "            inputs = F.log_softmax(outs, dim=2)\n",
    "            input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "            loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "            fake_val_loss_buffer.append(loss.detach())\n",
    "    \n",
    "    # model.eval()\n",
    "    # real_val_loss_buffer = []\n",
    "    # with torch.no_grad():\n",
    "    #     for features, labels in tqdm(real_val_loader):\n",
    "    #         features = features.to(device)\n",
    "    #         targets, target_lengths = batch_text_transform(labels)\n",
    "    #         targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "    #         outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "    #         inputs = F.log_softmax(outs, dim=2)\n",
    "    #         input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "    #         loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "    #         real_val_loss_buffer.append(loss.detach())\n",
    "\n",
    "    fake_train_loss_value = torch.mean(torch.stack(fake_train_loss_buffer)).item()\n",
    "    fake_val_loss_value = torch.mean(torch.stack(fake_val_loss_buffer)).item()\n",
    "    # real_val_loss_value = torch.mean(torch.stack(real_val_loss_buffer)).item()\n",
    "\n",
    "    print('train: ', fake_train_loss_value)\n",
    "    print('test:  ', fake_val_loss_value)\n",
    "    # print('real val', real_val_loss_value)\n",
    "        # wandb.log({\n",
    "        #     'train_loss': train_loss_value,\n",
    "        #     'test_loss': test_loss_value,\n",
    "        #     'lr': scheduler.get_last_lr()[0],\n",
    "        # })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 16.22it/s]\n"
     ]
    }
   ],
   "source": [
    "star_filenames = test_df['id'][-17:][:6]\n",
    "star_morse = [\n",
    "    '-.. .- -- .. -. .- -- - / -.. --- - .. / .-. ... -.-- ... .- -- -.-. ..',\n",
    "    '.. .-.. / -..- ... .-- . -.. - -.- ---. .-- -. - .. / .-.- -- -.. -- -.-- -- ..-- -. .-.- -- -.-. / ..-- - .. -.-- -- -..- - -.- - ---. -- -.-- -. / -.. - -.-- -- .-. --. --.. / . .--. .. --.',\n",
    "    '.- -. .... / .-- ... --- . --. -..- / .-. / .-- -.- - -.. .- -- .. / -. -.- ---- -- -.. -. .. / --. . -.- -. ...- - .-',\n",
    "    '.. .-.. / -.. .- ... -.. .--. / -..- ... --- . -- ..- -. - .. / .. --. .-- -.- ... --- . .--. / -..- -.- ... .... -.-- ... ..- ... / .... -. ..- / ..-- -. / .... -. .... -. ..- ... ..',\n",
    "    '. - -..- - -.- .--. / -.. ... .-.- -. -.- -- -.-- --- -.-. / .. -- -.-',\n",
    "    '-.- -. --- -..- -.- -- / ... --- . -. -.-- -- --- .--. / -..- ... ..-- -. .-- --',\n",
    "]\n",
    "star_dataset = read_dataset_from_files(audio_dir, filenames=star_filenames, labels=[decode_from_morse(m) for m in star_morse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 67.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.236782550811768\n",
      "34.166666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "star_loss_buffer = []\n",
    "star_len_buffer = []\n",
    "with torch.no_grad():\n",
    "    for features, labels in tqdm(star_dataset):\n",
    "        features = features[None]\n",
    "        labels = [labels]\n",
    "        features = features.to(device)\n",
    "        targets, target_lengths = batch_text_transform(labels)\n",
    "        targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "        outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "        inputs = F.log_softmax(outs, dim=2)\n",
    "        input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "        loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "        star_len_buffer.append(len(labels[0]))\n",
    "        star_loss_buffer.append(loss.detach())\n",
    "print(torch.mean(torch.stack(star_loss_buffer, dim=0)).item())\n",
    "print(np.mean(star_len_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ИЛ ЬСВЕДТКЧВНТИ ЯМДМЫМЮНЯМЦ ЮТИЫМЬТКТЧМЫН ДТЫМРГЗ ЕПИГ\n",
      ".. .-.. / -..- ... .-- . -.. - -.- ---. .-- -. - .. / .-.- -- -.. -- -.-- -- ..-- -. .-.- -- -.-. / ..-- - .. -.-- -- -..- - -.- - ---. -- -.-- -. / -.. - -.-- -- .-. --. --.. / . .--. .. --.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24cee565ad0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "star_mel, star_message = star_dataset[1]\n",
    "\n",
    "print(star_message)\n",
    "print(encode_to_morse(star_message))\n",
    "plt.imshow(star_mel[:, :600], aspect=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{run_name}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
