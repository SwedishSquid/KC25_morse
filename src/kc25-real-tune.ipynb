{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KC25_morse'...\r\n",
      "remote: Enumerating objects: 114, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (114/114), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (81/81), done.\u001b[K\r\n",
      "remote: Total 114 (delta 64), reused 79 (delta 29), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (114/114), 16.83 MiB | 33.39 MiB/s, done.\r\n",
      "Resolving deltas: 100% (64/64), done.\r\n"
     ]
    }
   ],
   "source": [
    "# run in kaggle to fetch repo\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "GITHUB_TOKEN = user_secrets.get_secret(\"GITHUB_MORSE_TOKEN\")\n",
    "USER = \"SwedishSquid\"\n",
    "REPO_NAME = 'KC25_morse'\n",
    "CLONE_URL = f\"https://{USER}:{GITHUB_TOKEN}@github.com/{USER}/{REPO_NAME}.git\"\n",
    "get_ipython().system(f\"git clone {CLONE_URL}\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/KC25_morse/src\")\n",
    "\n",
    "import morse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Levenshtein\r\n",
      "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\r\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\r\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\r\n",
      "Successfully installed Levenshtein-0.27.1 rapidfuzz-3.13.0\r\n",
      "Collecting MorseCodePy\r\n",
      "  Downloading morsecodepy-4.1.tar.gz (9.5 kB)\r\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Building wheels for collected packages: MorseCodePy\r\n",
      "  Building wheel for MorseCodePy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for MorseCodePy: filename=morsecodepy-4.1-py3-none-any.whl size=10436 sha256=e75c41630d51b6cd856b1f67bb1501a9d98047ed2e2db3138a4598dbf14add2b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/53/d8/509247fdfc5da7dca8ed7c371f13a91fc94fc83c12cb8ce4e6\r\n",
      "Successfully built MorseCodePy\r\n",
      "Installing collected packages: MorseCodePy\r\n",
      "Successfully installed MorseCodePy-4.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install Levenshtein\n",
    "!pip install MorseCodePy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "secret_value_0 = UserSecretsClient().get_secret('WANDB_API_KEY')\n",
    "os.environ[\"WANDB_API_KEY\"] = secret_value_0\n",
    "\n",
    "common_wandb_kvals = {\n",
    "    'project': 'KC25',\n",
    "    'entity': 'fishwere',\n",
    "}\n",
    "\n",
    "# let there be no noise\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "import time\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "from morse.models import CNNResidualBlock, TransformerResidualBlock, PoolingTransition, CNNTransformer, CTCHead\n",
    "from morse.models import MySomething\n",
    "from morse.models import SimpleCNN\n",
    "from morse.my_datasets import ListDataset, load_tensors, filenames_to_torch\n",
    "from morse.samplers import LongCTCSampler\n",
    "# from morse.augmentations import rotation_transform, volume_signal_transform\n",
    "from morse.augmentations import make_volume_signal_transform, make_compose_transform, make_noise_signal_transform, make_runtime_rotation_transform, make_runtime_mel_bounded_noise_transform\n",
    "from morse.text_helpers import Vectorizer, encode_to_morse, decode_from_morse\n",
    "\n",
    "from morse.my_datasets import generate_dataset, read_dataset_from_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.opus</td>\n",
       "      <td>03ЩУЫЛПИГХ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.opus</td>\n",
       "      <td>ЪЛТ0ДС6А3Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.opus</td>\n",
       "      <td>5ЭКЫБЗХЯН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.opus</td>\n",
       "      <td>ЖЫЦОИ68КФ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.opus</td>\n",
       "      <td>32Ю7МЫ ЗЛ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     message\n",
       "0  1.opus  03ЩУЫЛПИГХ\n",
       "1  2.opus  ЪЛТ0ДС6А3Г\n",
       "2  3.opus   5ЭКЫБЗХЯН\n",
       "3  4.opus   ЖЫЦОИ68КФ\n",
       "4  5.opus   32Ю7МЫ ЗЛ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_dir = '/kaggle/input/kc25-dataset-copy'\n",
    "audio_dir = '/kaggle/input/kc25-dataset-copy/morse_dataset/morse_dataset'\n",
    "\n",
    "\n",
    "dev_flag = False\n",
    "\n",
    "\n",
    "full_train_df = pd.read_csv(Path(labels_dir, 'train.csv'))\n",
    "test_df = pd.read_csv(Path(labels_dir, 'test.csv'))\n",
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [03:23<00:00, 24.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_index, val_index = train_test_split(np.arange(full_train_df.shape[0]), test_size=1/6, shuffle=True, \n",
    "                                           random_state=42)\n",
    "real_val_set = read_dataset_from_files(audio_dir, \n",
    "                                       filenames = full_train_df.iloc[val_index]['id'], \n",
    "                                       labels=list(full_train_df.iloc[val_index]['message']))\n",
    "print(len(real_val_set))\n",
    "\n",
    "real_train_set = read_dataset_from_files(audio_dir, \n",
    "                                       filenames = full_train_df.iloc[train_index]['id'], \n",
    "                                       labels=list(full_train_df.iloc[train_index]['message']))\n",
    "print(len(real_train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '#', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я']\n",
      "44\n",
      "{' ': 0, '#': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, 'А': 12, 'Б': 13, 'В': 14, 'Г': 15, 'Д': 16, 'Е': 17, 'Ж': 18, 'З': 19, 'И': 20, 'Й': 21, 'К': 22, 'Л': 23, 'М': 24, 'Н': 25, 'О': 26, 'П': 27, 'Р': 28, 'С': 29, 'Т': 30, 'У': 31, 'Ф': 32, 'Х': 33, 'Ц': 34, 'Ч': 35, 'Ш': 36, 'Щ': 37, 'Ъ': 38, 'Ы': 39, 'Ь': 40, 'Э': 41, 'Ю': 42, 'Я': 43}\n",
      "tensor([27, 28, 20, 14, 17, 30,  0,  1])\n"
     ]
    }
   ],
   "source": [
    "index_to_letter = sorted(set(''.join(full_train_df['message'])))\n",
    "pad_value = 0\n",
    "print(index_to_letter)\n",
    "letter_to_index = dict([(letter, i) for i, letter in enumerate(index_to_letter)])\n",
    "dictionary_size = len(index_to_letter)\n",
    "print(dictionary_size)\n",
    "print(letter_to_index)\n",
    "\n",
    "vectorizer = Vectorizer(letter_to_index, index_to_letter)\n",
    "print(vectorizer.text_transform('ПРИВЕТ #'))\n",
    "\n",
    "\n",
    "def batch_text_transform(texts):\n",
    "    vecs, lengths = vectorizer.batch_text_transform(texts, pad_value=pad_value)\n",
    "    return vecs + 1, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_target_metric(valset, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        distance_buffer = []\n",
    "        for features, labels in tqdm([valset[i] for i in range(700, 700 + 500)]):\n",
    "            features = features.to(device)\n",
    "            outs = model(features[None]).squeeze().to('cpu')\n",
    "            probs = F.softmax(outs, dim=0)\n",
    "            seqs, likelihood = LongCTCSampler.sample(probs, beam_size=10)\n",
    "            text = vectorizer.from_tensor(torch.tensor(seqs) - 1)\n",
    "            decoded_message = text\n",
    "            dist = Levenshtein.distance(decoded_message, labels)\n",
    "            distance_buffer.append(dist)\n",
    "        mean_dist = np.mean(distance_buffer)\n",
    "    return mean_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_period = 10\n",
    "\n",
    "n_epochs = 3 if dev_flag else 30\n",
    "batch_size = 128\n",
    "\n",
    "lr = 3e-4\n",
    "step_gamma = 0.33\n",
    "dropout = 0.165\n",
    "\n",
    "n_pools = 4\n",
    "n_blocks_before_pool = 3\n",
    "pooling_overlap = True\n",
    "\n",
    "group = 'RealTune'\n",
    "\n",
    "run_name = 'testrun' if dev_flag else 'SimpleCNN_baseline'\n",
    "\n",
    "config = {\n",
    "    'n_epochs': n_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    \n",
    "    'lr': lr,\n",
    "    'step_gamma': step_gamma,\n",
    "    'dropout': dropout,\n",
    "\n",
    "    'n_pools': n_pools,\n",
    "    'n_blocks_before_pool': n_blocks_before_pool,\n",
    "    'pooling_overlap': pooling_overlap,\n",
    "}\n",
    "\n",
    "model = SimpleCNN(d_input=64, d_model=64, d_inner=64, d_output=dictionary_size + 1, \n",
    "              n_pools=n_pools, n_blocks_before_pool=n_blocks_before_pool, pooling_overlap=pooling_overlap,\n",
    "              dropout=dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:12<00:00, 18.64it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.58it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.210727262496949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 37.08it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.960347661972046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.29it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.36it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.314725569605827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.33it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.85it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 39.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.166647103631496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.30it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.70it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3393262873518466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.35it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7614910895923375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.36it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.97it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3566136237690567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.71it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.062861314783176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.40it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8549210071154197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.34it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.66it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7104847687196167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.36it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.10it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 41.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6127140134968363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.78it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.550962653485795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.34it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.14it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5014898992672583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.35it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.64it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.471555912690015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.33it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.56it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4472293873008648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4405026479128591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.33it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.70it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42619568114424883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.34it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.74it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40954400006395175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.40it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.39it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4030538651587875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.42it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.25it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3940638469924149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.46it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.91it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 46.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39061361820387164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.49it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.38it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 46.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3870326359035683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.41it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.87it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3865367288662471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.26it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38745373693023466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.19it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.29it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3847221567714218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.31it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.48it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3824182961522343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.24it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 41.61it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3830247819321515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.29it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.88it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3843936204838766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.26it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.17it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3847901260802755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 45.85it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 44.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3828575755322701\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20], gamma=step_gamma)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(real_train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(real_val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "with wandb.init(\n",
    "    **common_wandb_kvals,\n",
    "    group=group,\n",
    "    config=config,\n",
    "    name=run_name,\n",
    "    ) as run:\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        fake_train_loss_buffer = []\n",
    "        for features, labels in tqdm(train_loader):\n",
    "            features = features.to(device)\n",
    "            targets, target_lengths = batch_text_transform(labels)\n",
    "            targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "            outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "            inputs = F.log_softmax(outs, dim=2)\n",
    "            input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "            loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            fake_train_loss_buffer.append(loss.detach())\n",
    "        scheduler.step()\n",
    "    \n",
    "        model.eval()\n",
    "        fake_val_loss_buffer = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in tqdm(val_loader):\n",
    "                features = features.to(device)\n",
    "                targets, target_lengths = batch_text_transform(labels)\n",
    "                targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "                outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "                inputs = F.log_softmax(outs, dim=2)\n",
    "                input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "                loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "                fake_val_loss_buffer.append(loss.detach())\n",
    "    \n",
    "        fake_train_loss_value = torch.mean(torch.stack(fake_train_loss_buffer)).item()\n",
    "        fake_val_loss_value = torch.mean(torch.stack(fake_val_loss_buffer)).item()\n",
    "\n",
    "        wandb.log({\n",
    "            'fake_train_loss': fake_train_loss_value,\n",
    "            'fake_val_loss': fake_val_loss_value,\n",
    "            'lr': scheduler.get_last_lr()[0],\n",
    "        })\n",
    "\n",
    "        if (epoch + 1) % checkpoint_period == 0:\n",
    "            torch.save(model.state_dict(), f'{run_name}_{epoch+1}ep.pt')\n",
    "            print('saved model')\n",
    "    print('calculating target metric')\n",
    "    target_metric = calculate_target_metric(real_val_set, model)\n",
    "    # time_spent_on_train = time.perf_counter() - train_start_time\n",
    "    wandb.log({\n",
    "        'Levenshtein_distance': target_metric,\n",
    "        # 'final_loss': final_loss,\n",
    "        # 'mean_epoch_duration': time_spent_on_train / n_epochs,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{run_name}_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
