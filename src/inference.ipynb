{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "import time\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "from morse.models import CNNResidualBlock, TransformerResidualBlock, PoolingTransition, CNNTransformer, CTCHead\n",
    "from morse.models import MySomething\n",
    "from morse.models import SimpleCNN\n",
    "from morse.my_datasets import ListDataset, load_tensors, filenames_to_torch\n",
    "from morse.samplers import LongCTCSampler\n",
    "# from morse.augmentations import rotation_transform, volume_signal_transform\n",
    "from morse.augmentations import make_volume_signal_transform, make_compose_transform, make_noise_signal_transform, make_runtime_rotation_transform, make_runtime_mel_bounded_noise_transform\n",
    "from morse.text_helpers import Vectorizer, encode_to_morse, decode_from_morse\n",
    "\n",
    "from morse.my_datasets import generate_dataset, read_dataset_from_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.opus</td>\n",
       "      <td>03ЩУЫЛПИГХ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.opus</td>\n",
       "      <td>ЪЛТ0ДС6А3Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.opus</td>\n",
       "      <td>5ЭКЫБЗХЯН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.opus</td>\n",
       "      <td>ЖЫЦОИ68КФ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.opus</td>\n",
       "      <td>32Ю7МЫ ЗЛ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     message\n",
       "0  1.opus  03ЩУЫЛПИГХ\n",
       "1  2.opus  ЪЛТ0ДС6А3Г\n",
       "2  3.opus   5ЭКЫБЗХЯН\n",
       "3  4.opus   ЖЫЦОИ68КФ\n",
       "4  5.opus   32Ю7МЫ ЗЛ"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dir = '../'\n",
    "# data_dir = '../data/melspec_nfft512_nc64'\n",
    "audio_dir = '../morse_dataset'\n",
    "\n",
    "full_train_df = pd.read_csv(Path(labels_dir, 'train.csv'))\n",
    "test_df = pd.read_csv(Path(labels_dir, 'test.csv'))\n",
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '#', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я']\n",
      "44\n",
      "{' ': 0, '#': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, 'А': 12, 'Б': 13, 'В': 14, 'Г': 15, 'Д': 16, 'Е': 17, 'Ж': 18, 'З': 19, 'И': 20, 'Й': 21, 'К': 22, 'Л': 23, 'М': 24, 'Н': 25, 'О': 26, 'П': 27, 'Р': 28, 'С': 29, 'Т': 30, 'У': 31, 'Ф': 32, 'Х': 33, 'Ц': 34, 'Ч': 35, 'Ш': 36, 'Щ': 37, 'Ъ': 38, 'Ы': 39, 'Ь': 40, 'Э': 41, 'Ю': 42, 'Я': 43}\n",
      "tensor([27, 28, 20, 14, 17, 30,  0,  1])\n"
     ]
    }
   ],
   "source": [
    "index_to_letter = sorted(set(''.join(full_train_df['message'])))\n",
    "pad_value = 0\n",
    "print(index_to_letter)\n",
    "letter_to_index = dict([(letter, i) for i, letter in enumerate(index_to_letter)])\n",
    "dictionary_size = len(index_to_letter)\n",
    "print(dictionary_size)\n",
    "print(letter_to_index)\n",
    "\n",
    "vectorizer = Vectorizer(letter_to_index, index_to_letter)\n",
    "print(vectorizer.text_transform('ПРИВЕТ #'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_period = 10\n",
    "\n",
    "# n_epochs = 3 if dev_flag else 30\n",
    "# batch_size = 128\n",
    "\n",
    "# lr = 1e-3\n",
    "# step_gamma = 0.33\n",
    "# dropout = 0.165\n",
    "\n",
    "# n_pools = 4\n",
    "# n_blocks_before_pool = 3\n",
    "# pooling_overlap = True\n",
    "\n",
    "# group = 'RealTune'\n",
    "\n",
    "# run_name = 'testrun' if dev_flag else 'CNNTransformer_pretrained_30ep__lr=1e-4'\n",
    "\n",
    "\n",
    "\n",
    "# model = SimpleCNN(d_input=64, d_model=64, d_inner=64, d_output=dictionary_size + 1, \n",
    "#               n_pools=n_pools, n_blocks_before_pool=n_blocks_before_pool, pooling_overlap=pooling_overlap,\n",
    "#               dropout=dropout).to(device)\n",
    "\n",
    "batch_size = 256\n",
    "lr = 1e-4\n",
    "step_gamma = 0.051\n",
    "dropout = 0.0838\n",
    "\n",
    "d_input = 64\n",
    "d_model = 128\n",
    "d_inner = 128\n",
    "d_output = dictionary_size + 1\n",
    "\n",
    "n_pools = 4\n",
    "n_blocks_before_pool = 3\n",
    "n_transformer_blocks = 5\n",
    "num_heads = 4       # might be important\n",
    "\n",
    "# config = {\n",
    "#     'n_epochs': n_epochs,\n",
    "#     'batch_size': batch_size,\n",
    "    \n",
    "#     'lr': lr,\n",
    "#     'step_gamma': step_gamma,\n",
    "#     'dropout': dropout,\n",
    "\n",
    "#     'n_pools': n_pools,\n",
    "#     'n_blocks_before_pool': n_blocks_before_pool,\n",
    "#     'pooling_overlap': True,\n",
    "#     'n_transformer_blocks': n_transformer_blocks,\n",
    "#     'num_heads': num_heads,\n",
    "\n",
    "#     'd_input': d_input,\n",
    "#     'd_model': d_model,\n",
    "#     'd_inner': d_inner,\n",
    "#     'd_output': d_output,\n",
    "# }\n",
    "\n",
    "model = CNNTransformer(d_input = d_input, d_model=d_model,\n",
    "    n_pools=n_pools, n_blocks_before_pool=n_blocks_before_pool,\n",
    "    n_transformer_blocks=n_transformer_blocks,\n",
    "    dropout=dropout,\n",
    "    head_block=CTCHead(d_model, d_output),\n",
    "    make_cnn_block=lambda: CNNResidualBlock(d_model, d_inner, dropout=dropout),\n",
    "    make_transformer_block=lambda: TransformerResidualBlock(d_model, d_ffn=d_inner, dropout=dropout, num_heads=num_heads), \n",
    "    pooling_overlap=True).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('../models/CNNTransformer_pretrained_30ep__lr=1e-4_30ep.pt', \n",
    "                                 weights_only=True, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:03<00:00, 78.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_index, val_index = train_test_split(np.arange(full_train_df.shape[0]), test_size=1/6, shuffle=True, \n",
    "                                           random_state=42)\n",
    "real_val_set = read_dataset_from_files(audio_dir, \n",
    "                                       filenames = full_train_df.iloc[val_index]['id'], \n",
    "                                       labels=list(full_train_df.iloc[val_index]['message']))\n",
    "print(len(real_val_set))\n",
    "\n",
    "# real_train_set = read_dataset_from_files(audio_dir, \n",
    "#                                        filenames = full_train_df.iloc[train_index]['id'], \n",
    "#                                        labels=list(full_train_df.iloc[train_index]['message']))\n",
    "# print(len(real_train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batch_text_transform(texts):\n",
    "#     vecs, lengths = vectorizer.batch_text_transform(texts, pad_value=pad_value)\n",
    "#     return vecs + 1, lengths\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_index, val_index = train_test_split(np.arange(full_train_df.shape[0]), test_size=1/6, shuffle=True, \n",
    "#                                            random_state=42)\n",
    "# print(train_index.shape, val_index.shape)\n",
    "# val_features = list(tqdm(load_tensors(data_dir, filenames_to_torch(list(full_train_df.iloc[val_index]['id'])))))\n",
    "# val_labels = list(full_train_df.iloc[val_index]['message'])\n",
    "# valset = ListDataset(val_features, val_labels)\n",
    "# print(len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:10, 92.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generator = (real_val_set[i] for i in range(1000))\n",
    "\n",
    "val_ctc_probs = []\n",
    "val_ctc_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for features, labels in tqdm(generator):\n",
    "        features = features.to(device)\n",
    "        outs = model(features[None]).squeeze().to('cpu')\n",
    "        probs = F.softmax(outs, dim=0)\n",
    "        val_ctc_probs.append(probs)\n",
    "        val_ctc_labels.append(labels)\n",
    "\n",
    "print(len(val_ctc_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:06<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "distance_buffer = []\n",
    "for prob, label in zip(tqdm(val_ctc_probs), val_ctc_labels):\n",
    "    seqs, likelihood = LongCTCSampler.sample(prob, beam_size=10)\n",
    "    text = vectorizer.from_tensor(torch.tensor(seqs) - 1)\n",
    "    # print(text, label)\n",
    "    decoded_message = text\n",
    "    dist = Levenshtein.distance(decoded_message, label)\n",
    "    # print(dist)\n",
    "    distance_buffer.append(dist)\n",
    "val_mean_dist = np.mean(distance_buffer)\n",
    "print(val_mean_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:00<00:00, 82.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_set = read_dataset_from_files(audio_dir, \n",
    "                                       filenames = test_df['id'], \n",
    "                                       labels=['' for i in range(5000)])\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "test_features = [test_set[i][0] for i in range(len(test_set))]\n",
    "print(len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:53<00:00, 93.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_ctc_probs = []\n",
    "# val_ctc_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for features in tqdm(test_features):\n",
    "        features = features.to(device)\n",
    "        outs = model(features[None]).squeeze().to('cpu')\n",
    "        probs = F.softmax(outs, dim=0)\n",
    "        test_ctc_probs.append(probs)\n",
    "        # val_ctc_labels.append(labels)\n",
    "\n",
    "print(len(test_ctc_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [05:07<00:00, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_decoded_list = []\n",
    "for prob in tqdm(test_ctc_probs):\n",
    "    seqs, likelihood = LongCTCSampler.sample(prob, beam_size=10)\n",
    "    text = vectorizer.from_tensor(torch.tensor(seqs) - 1)\n",
    "    test_decoded_list.append(text)\n",
    "print(len(test_decoded_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30001.opus</td>\n",
       "      <td>ЯЮ6ЛИТЖБШ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30002.opus</td>\n",
       "      <td>КЩ В9Ю 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30003.opus</td>\n",
       "      <td>Ы65Ф61Я</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30004.opus</td>\n",
       "      <td>ЖЖНЖ9РЫНЦ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30005.opus</td>\n",
       "      <td>ЕЯФ4ЮЧЬ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     message\n",
       "0  30001.opus   ЯЮ6ЛИТЖБШ\n",
       "1  30002.opus    КЩ В9Ю 9\n",
       "2  30003.opus     Ы65Ф61Я\n",
       "3  30004.opus  ЖЖНЖ9РЫНЦ3\n",
       "4  30005.opus     ЕЯФ4ЮЧЬ"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'id': test_df['id'], 'message': test_decoded_list})\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('../submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
