{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in kaggle to fetch repo\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "GITHUB_TOKEN = user_secrets.get_secret(\"GITHUB_MORSE_TOKEN\")\n",
    "USER = \"SwedishSquid\"\n",
    "REPO_NAME = 'KC25_morse'\n",
    "CLONE_URL = f\"https://{USER}:{GITHUB_TOKEN}@github.com/{USER}/{REPO_NAME}.git\"\n",
    "get_ipython().system(f\"git clone {CLONE_URL}\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/KC25_morse/src\")\n",
    "\n",
    "import morse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import Levenshtein\n",
    "import time\n",
    "\n",
    "from morse.models import MySomething\n",
    "from morse.my_datasets import ListDataset, load_tensors, filenames_to_torch\n",
    "from morse.samplers import LongCTCSampler\n",
    "from morse.augmentations import rotation_transform\n",
    "from morse.text_helpers import Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "secret_value_0 = UserSecretsClient().get_secret('WANDB_API_KEY')\n",
    "os.environ[\"WANDB_API_KEY\"] = secret_value_0\n",
    "\n",
    "common_wandb_kvals = {\n",
    "    'project': 'KC25',\n",
    "    'entity': 'fishwere',\n",
    "}\n",
    "\n",
    "# let there be no noise\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_flag = False\n",
    "\n",
    "all_data_dir = '/kaggle/input/kc25-preprocessed-data'\n",
    "labels_dir = '/kaggle/input/kc25-dataset-copy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df = pd.read_csv(Path(labels_dir, 'train.csv'))\n",
    "test_df = pd.read_csv(Path(labels_dir, 'test.csv'))\n",
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_letter = sorted(set(''.join(full_train_df['message'])))\n",
    "pad_value = 0\n",
    "print(index_to_letter)\n",
    "letter_to_index = dict([(letter, i) for i, letter in enumerate(index_to_letter)])\n",
    "dictionary_size = len(index_to_letter)\n",
    "print(dictionary_size)\n",
    "print(letter_to_index)\n",
    "\n",
    "vectorizer = Vectorizer(letter_to_index, index_to_letter)\n",
    "print(vectorizer.text_transform('ПРИВЕТ #'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    train_index, val_index = train_test_split(np.arange(full_train_df.shape[0]), test_size=1/6, shuffle=True, \n",
    "                                           random_state=42)\n",
    "    if dev_flag:\n",
    "        train_index = train_index[:1000]    # to save memory\n",
    "        val_index = val_index[:1000]\n",
    "\n",
    "    print(train_index.shape, val_index.shape)\n",
    "\n",
    "    train_features = list(tqdm(load_tensors(data_dir, filenames_to_torch(list(full_train_df.iloc[train_index]['id'])))))\n",
    "    val_features = list(tqdm(load_tensors(data_dir, filenames_to_torch(list(full_train_df.iloc[val_index]['id'])))))\n",
    "    train_labels = list(full_train_df.iloc[train_index]['message'])\n",
    "    val_labels = list(full_train_df.iloc[val_index]['message'])\n",
    "\n",
    "    assert len(train_features) == len(train_labels)\n",
    "    assert len(val_features) == len(val_labels)\n",
    "\n",
    "    trainset = ListDataset(train_features, train_labels, transform=rotation_transform)\n",
    "    valset = ListDataset(val_features, val_labels)\n",
    "\n",
    "    return trainset, valset\n",
    "\n",
    "    # print(len(trainset), len(valset))\n",
    "    # plt.imshow(valset[0][0])\n",
    "    # print(valset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = load_data(Path(all_data_dir, 'melspec_nfft512_nc64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4, ff_dim=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(dim, num_heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_len, batch, features)\n",
    "        attn_out, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ff_out = self.ff(x)\n",
    "        return self.norm2(x + ff_out)\n",
    "\n",
    "class CNNTransformerModel(nn.Module):\n",
    "    def __init__(self, input_size=64, inner_size=64, output_size=5):\n",
    "        super().__init__()\n",
    "        # CNN feature extractor\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_size, inner_size, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(inner_size),\n",
    "            nn.MaxPool1d(2, stride=2),\n",
    "            nn.Conv1d(inner_size, inner_size, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(inner_size),\n",
    "            nn.MaxPool1d(2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Transformer\n",
    "        self.transformer = TransformerBlock(inner_size)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.AdaptiveAvgPool1d(1),\n",
    "            # nn.Flatten(),\n",
    "            nn.Linear(inner_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        x = self.cnn(x)  # (batch, channels, seq_len)\n",
    "        \n",
    "        # Prepare for transformer\n",
    "        x = x.permute(2, 0, 1)  # (seq_len, batch, channels)\n",
    "        \n",
    "        # Transformer\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Classifier\n",
    "        x = x.permute(1, 2, 0)  # (batch, channels, seq_len)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_text_transform(texts):\n",
    "    vecs, lengths = vectorizer.batch_text_transform(texts, pad_value=pad_value)\n",
    "    return vecs + 1, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_target_metric(valset, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        distance_buffer = []\n",
    "        for features, labels in tqdm([valset[i] for i in range(250)]):\n",
    "            features = features.to(device)\n",
    "            outs = model(features[None]).squeeze().to('cpu')\n",
    "            probs = F.softmax(outs, dim=0)\n",
    "            seqs, likelihood = LongCTCSampler.sample(probs, beam_size=10)\n",
    "            text = vectorizer.from_tensor(torch.tensor(seqs) - 1)\n",
    "            decoded_message = text\n",
    "            dist = Levenshtein.distance(decoded_message, labels)\n",
    "            distance_buffer.append(dist)\n",
    "        mean_dist = np.mean(distance_buffer)\n",
    "    return mean_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 128\n",
    "lr = 5e-3\n",
    "inner_size = 64\n",
    "step_gamma = 0.33\n",
    "p_dropout = 0.15\n",
    "input_size = 64\n",
    "\n",
    "group = 'CNNTransformer'\n",
    "run_name = 'proof_of_concept'\n",
    "\n",
    "config = {\n",
    "    'n_epochs': n_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'lr': lr,\n",
    "    'inner_size': inner_size,\n",
    "    'step_gamma': step_gamma,\n",
    "    'p_dropout': p_dropout,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model = CNNTransformerModel(input_size=input_size, inner_size=inner_size, output_size=dictionary_size + 1)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20], gamma=step_gamma)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "final_loss = 100\n",
    "with wandb.init(\n",
    "        **common_wandb_kvals,\n",
    "        group=group,\n",
    "        config=config,\n",
    "        name=run_name,\n",
    "        ) as run:\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss_buffer = []\n",
    "        epoch_start_time = time.perf_counter()\n",
    "        for features, labels in tqdm(train_loader):\n",
    "            features = features.to(device)\n",
    "            targets, target_lengths = batch_text_transform(labels)\n",
    "            targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "            outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "            inputs = F.log_softmax(outs, dim=2)\n",
    "            input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "            loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss_buffer.append(loss.detach())\n",
    "        scheduler.step()\n",
    "        model.eval()\n",
    "        test_loss_buffer = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in tqdm(val_loader):\n",
    "                features = features.to(device)\n",
    "                targets, target_lengths = batch_text_transform(labels)\n",
    "                targets, target_lengths = targets.to(device), target_lengths.to(torch.int32).to(device)\n",
    "                outs = model(features).transpose(0, 2).transpose(1, 2)\n",
    "                inputs = F.log_softmax(outs, dim=2)\n",
    "                input_lengths = torch.full(size=(inputs.shape[1],), fill_value=inputs.shape[0], dtype=torch.int32).to(device)\n",
    "                loss = ctc_loss(inputs, targets, input_lengths, target_lengths)\n",
    "                test_loss_buffer.append(loss.detach())\n",
    "        train_loss_value = torch.mean(torch.stack(train_loss_buffer)).item()\n",
    "        test_loss_value = torch.mean(torch.stack(test_loss_buffer)).item()\n",
    "        final_loss = test_loss_value\n",
    "        wandb.log({\n",
    "            'train_loss': train_loss_value,\n",
    "            'test_loss': test_loss_value,\n",
    "            'lr': scheduler.get_last_lr()[0],\n",
    "            'epoch_duration': (time.perf_counter() - epoch_start_time),\n",
    "        })\n",
    "    print('calculating target metric')\n",
    "    target_metric = calculate_target_metric(valset, model)\n",
    "    wandb.log({\n",
    "        'Levenshtein_distance': target_metric,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
