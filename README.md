# Morse

## Структура репозитория

основной код находится в `/src/morse`; также в `/src` есть ноутбуки, его использующие; вне `/src` находятся преимущественно старые файлы, утратившие свою актуальность. Не удаляю их т.к. они отражают пройденный путь

Еще есть `/kaggle_notebooks` - там я сохранил ноутбуки, использованные для тренировки лучшей модели в моей серии (большой версии cnn transformer):

- [`kc25-make-small-mels.ipynb`](./kaggle_notebooks/kc25-make-small-mels.ipynb) - переводит исходные данные в более удобоваримый формат
- [`kc25-synthetic-fe-train.ipynb`](./kaggle_notebooks/kc25-synthetic-fe-train.ipynb) - предобучение на синтетических данных
- [`kc25-real-tune.ipynb`](./kaggle_notebooks/kc25-real-tune.ipynb) - тюнинг на реальных данных

есть ```requirements.txt``` - сгенерирован в kaggle ноутбуке со всеми зависимостями

ссылка на этот репозиторий https://github.com/SwedishSquid/KC25_morse

## Описание решения

сделал ноутбук, повторяющий цепочку действий, завершающуюся получением submission.csv (ну почти) - это [`src\submission_replication.ipynb`](./src/kc25-submission-replication.ipynb) - там более подробное описание

отправил результат в kaggle как late submission. результат чуть хуже, чем финальный, но не катастрофично

```replicated_submission.csv``` прикладываю

### обработка данных

звук преобразую в мел-спектрограммы, после чего вырезаю 4 канала вокруг области, предположительно содержащей сигнал (через усреднение значения в каждом канале + argmax) - это довольно важный шаг, т.к. сильно концентрирует сигнал

чтобы лучше адаптировать модель к ситуациям, когда сигнал не идеально выровнен, применяю аугментацию, проворачивающую полученную 4-x канальную спектрограмму (в ноутбуке для воспроизведения есть картинки)

### модель

модель написана на `pytorch` и состоит из 2 последовательных блоков (и головы):

- 1d CNN на 25 слоев -> уменьшает длину последовательности в 2^4 = 16 раз
- 5 слоев encoder only transformer

обучал это с помощью ctc лосса, предсказывает символы

для семплирования из предсказаний модели использовал beamsearch, взятый отсюда https://gist.github.com/awni/56369a90d03953e370f3964c826ed4b0

это код к следующей статье: Hannun, "Sequence Modeling with CTC", Distill, 2017.

### дополнительные данные

сделал генерацию синтетических данных для предобучения модели. соответственно, обучение было 2х ступенчатым - сначала на большом синтетическом датасете, затем на оригинальном

### генерация submission

подробно можно посмотреть в [`src\inference.ipynb`](./src/inference.ipynb) - я объединил в ансамбль несколько полученных в процессе экспериментов моделей - путем усреднения предсказаний. также применил test-time аугментации (поворотные)

веса моделей, использованных в `src\inference.ipynb` доступны по ссылке https://www.kaggle.com/models/alexeydzhevello/kc25_models/pyTorch/used-for-final-submission

в итоге в ансамбле были следующие вариации модели:

- 2 чекпоинта модели, предобученной на 120k синтетическом датасете (x4 для краткости) без поворотной аугментации
- 2 предсказания с разными поворотами модели, обученной на x4 с поворотными аугментациями
- 2 предсказания с разными поворотами модели, обученной на x12 с поворотными аугментациями
- 2 модели с удвоенным размером внутреннего состояния по 2 предсказания с разными поворотами. модели отличались долей дропаута
